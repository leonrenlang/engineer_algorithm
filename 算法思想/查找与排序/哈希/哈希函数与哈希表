


哈希函数：
    1.输入域是无限的（f域）
    2.输出域是有穷的（s域）
        比如2^64,16个十六进制数
    3.（精）如果有很多不同的输入的话，将在整个s域均匀的出现其返回值，
        且返回值与原始的输入规律是没有关系的(因此简单取模不是哈希函数)
    推论：
        1. 哈希域一般比较大，将每个input的哈希值mod m(实际使用一般会返回这个m值),哈希函数在这个
        m域上也是均匀分布的。
        2. 当有一个哈希函数时，可以通过以下方法获得1000个相互独立哈希函数。
            h = hash(input)
            h = h1, h2
            h' = h1 + h2*i  (2<=i<=1001)      '
            （因为哈希函数的每一位也是独立的）
    - 常用哈希算法(指的是哈希函数)
        MD5, SHA1


哈希表: 
    - 哈希表是利用哈希函数构造的一种数据结构
    - 经典哈希表
        增
        - 表长为table_length,   将数据放在 hash(key) mod table_length的位置
        - 例如：对于一个key，将key输入hash函数获取其hash值。假设hash表的表长为16，将hash值mod 16，假如结果为5，结果加到
        hash表中第五个桶中。
        - 如果桶内已经有元素（相同的key，对比其值），则需要处理冲突
        查
        - hash(key) mod table_length
        删
        - 找到相应的键值对，如果是链表形式存储，则保留上一个
        改
        - 找到相应的键值对，修改
        扩容：
        - 因为hash值是均匀分布的，当某个桶内数据(经典结构是一个链表）到达一定数量，认为hash表的效率可能下降，
        - 行扩容。
            关于扩容的时间损耗，如果每次扩容增加一倍，对整个N条数据，需要扩容logn次，数学上不是O(1)
            实际工程中甚至可以离线扩容，扩容完成再替换,则为O(1)
            JVM里面每个桶对应一个红黑树（平衡搜索二叉树）
            开放地址法就是当前桶放不下了，按一定规则放到其他桶里
            增大hash表的表长，对表内的每一个值重新计算hash值，重新放入。
    - 实际使用的时候可以认为哈希表的CRUD都是O(1)
        因为每个桶内的数据量应该非常小







哈希函数的应用
    注：大数据的题有一大部分都可以用hash函数来解决，将大问题转换成小问题
    负载均衡
        经典服务器抗压结构
            - 一个前端服务器，假设有128台后端服务器,对于每一个请求，求hash值，mod128,将请求送到对应的
                后端服务器上。（负载均衡）
            - 如果要增减机器，这种结构就有问题，相当于hash表扩容，要对所有数据进行迁移
        一致性哈希，解决增删机器的问题
            - 目的就是又能负载均衡，又能增减机器
            - 把hash函数的output域,比如说0~pow(2,64)-1
            - 将后台机器的特有信息，比如说IP，对其求hash函数，打到环上
            - 如果要新增数据，将数据打到环上，顺时针，找到对应后台机器
                后台机器hash值排序数组放到前端服务器上，前端服务器就能使用二分找到对应服务器
            - 新增一台服务器m4，比如哈希值说在m2和m3之间，仅需将m2到m4的数据迁移到m4
            - 删除一台服务器,原来是m1,m2,m3,删除m2,将m2所有的数据放到m3上
        进一步扩展：
            问题：hash函数只有在数据量特别大的时候，才很均匀，很小的时候很难保证均匀
            - 虚拟节点技术
                -对于每台机器，给其造比如说1000个虚拟节点，这些节点打到环上
                -每台机器的虚拟节点负责的数据由真实机器来负责
                -这样，机器的数据增大了，hash就均匀了
    
    打印大文件中所有重复的字符串
        说明：大文件有100T,里面字符串是无序
        方法：
            假设有1000台机器，将大文件中每行计算hash code mod 1000,就能将文件分配到1000台机器
            这样，重复文本都会分配到同一台机器上，且不同种的字符串会均匀分布到一台机器上。
            如果还是太大，还可以继续分，就变成了正常打印重复的字符串问题
    布隆过滤器
        解决的问题:
            爬虫去重问题和黑名问题
            url黑名单问题
                - 如果有100亿url黑名单，这些黑名单是不给访问的，每个url64位
                - 需要一个函数，对于每个url，返回true或者false，其是否属于该黑名单
                - 如果使用hashset,则需要640G内存来存储这个hash表
                
                - 用k个哈希表，一个input，将其对应的k个位置都设为1
                - 存储结构采用bit的0,1存储
        过程：
            准备一个有m个bit位的数组
            准备K个hash函数
            生成黑名单
                对于一个url,分别进入K个哈希函数 mod m, 将其相应位置描黑,就说一个url进到了该数组了
            查找url是否在黑名单
                url,分别进入K个哈希函数 mod m, 如果全黑，则认为在黑名单中，否则不在
        关于失误率
            hash函数k的个数越多，失误率越小
            数组的空间越大，失误率越小
            失误类型是，宁可杀错，不可放过的类型 
            参数如何确定
                所需空间计算公式m = -1 * (n * lnP) / (ln2)^2
                    注：n是样本量，P是目标概率， m是数组大小(比特)
                所需哈希函数个数
                    k=ln2*m/n
                m,k确定之后，真实失误率
                    P = (1-e^(-(n*k/m)))
                例子：假设n = 100亿， P=万分之1，m大概是1310亿比特，也就是大约22.3g。需要哈希函数13个，真实失误率十万分之6。
            